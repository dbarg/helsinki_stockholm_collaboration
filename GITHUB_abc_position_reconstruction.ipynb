{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABC applied to position reconstruction\n",
    "\n",
    "*Bart Pelssers, 26-02-2018*\n",
    "\n",
    "This notebook provides some ingredients for applying the ABC algorithm to position reconstruction, the most basic case. Just to test the framework.\n",
    "\n",
    "\n",
    "* Provides:\n",
    "  * prior mean\n",
    "  * forward model\n",
    "  * summary statistic\n",
    "  \n",
    "*Umberto Simola, 22-03-2018*\n",
    "\n",
    "Provided the ABC-PMC algorithm for running the analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using the XENON1T data processor\n",
    "from pax import utils\n",
    "from pax.configuration import load_configuration\n",
    "from pax.PatternFitter import PatternFitter\n",
    "from pax.plugins.io.WaveformSimulator import uniform_circle_rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PriorPosition():\n",
    "    \"\"\"Implements the calculation of the mean of a prior\n",
    "       given a pattern (either from data or from the forward model)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Get some settings from the XENON1T detector configuration\n",
    "        config = load_configuration('XENON1T')\n",
    "        \n",
    "        # PMT positions\n",
    "        pmt_config = config['DEFAULT']['pmts']\n",
    "        \n",
    "        # List of dicts {'x': , 'y'}, which the position\n",
    "        self.positions = [pmt['position'] for pmt in pmt_config][:127]\n",
    "\n",
    "    def __call__(self, pattern):\n",
    "        # The id of the PMT that sees most light\n",
    "        max_pmt = np.argmax(pattern)\n",
    "        \n",
    "        # The position of that PMT\n",
    "        pos = self.positions[max_pmt]\n",
    "        \n",
    "        return pos['x'], pos['y']        \n",
    "        \n",
    "\n",
    "class Model():\n",
    "    \"\"\"Implements the forward model for ABC project.\n",
    "    \n",
    "       The forward model used here is the most basic test case.\n",
    "       It draws from the per-PMT S2 LCE maps to provide a\n",
    "       hitpattern for a given x,y. Assumes all top PMTs live.\n",
    "       Also the total number of detected photo-electrons needs to\n",
    "       be specified, this is set constant by default.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Get some settings from the XENON1T detector configuration\n",
    "        config = load_configuration('XENON1T')\n",
    "        \n",
    "        # The per-PMT S2 LCE maps (and zoom factor which is a technical detail)\n",
    "        lce_maps = config['WaveformSimulator']['s2_patterns_file']\n",
    "        lce_map_zoom = config['WaveformSimulator']['s2_patterns_zoom_factor']\n",
    "\n",
    "        # Simulate the right PMT response\n",
    "        qes = np.array(config['DEFAULT']['quantum_efficiencies'])\n",
    "        top_pmts = config['DEFAULT']['channels_top']\n",
    "        errors = config['DEFAULT']['relative_qe_error'] + config['DEFAULT']['relative_gain_error']\n",
    "\n",
    "        # Set up the PatternFitter which sample the LCE maps\n",
    "        self.pf = PatternFitter(filename=utils.data_file_name(lce_maps),\n",
    "                                zoom_factor=2*lce_map_zoom,\n",
    "                                adjust_to_qe=qes[top_pmts],\n",
    "                                default_errors=errors)\n",
    "\n",
    "    def __call__(self, x, y, n_obs = 500):\n",
    "        \"\"\"Returns a hitpattern of n_obs photo-electrons\n",
    "           for given x, y position.\n",
    "        \"\"\"\n",
    "        \n",
    "        return n_obs * self.pf.expected_pattern((x, y))\n",
    "\n",
    "\n",
    "class Generator():\n",
    "    \"\"\"Generates test hitpatterns by drawing from LCE maps (forward model)\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        # Get some settings from the XENON1T detector configuration\n",
    "        config = load_configuration('XENON1T')\n",
    "        self.tpc_radius = config['DEFAULT']['tpc_radius']\n",
    "        \n",
    "        # Use the forward model also as generator for now\n",
    "        self.model = model\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.model(*uniform_circle_rv(self.tpc_radius))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup the Models\n",
    "model = Model()\n",
    "prior_mean = PriorPosition()\n",
    "generator = Generator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pattern: 127, Sum of pattern: 500.00\n",
      "[   0.41645266    0.38856616    0.40444191    0.32748224    0.38441824\n",
      "    0.38170297    0.40477179    0.39144921    0.47687253    0.46203223\n",
      "    0.52646186    0.57781957    0.64051689    0.74521969    0.84447167\n",
      "    0.92923987    1.16943785    1.26806905    1.6059695     1.50876463\n",
      "    1.39647011    1.18050349    1.1130101     0.94818458    0.87288815\n",
      "    0.65681059    0.63291142    0.55729029    0.49757721    0.54446233\n",
      "    0.47297285    0.43356499    0.33506074    0.46603606    0.43350709\n",
      "    0.41858736    0.66362616    0.68610503    0.79095441    0.69480663\n",
      "    0.75740472    0.74267691    0.70961981    0.92924549    0.84056631\n",
      "    0.99494579    1.07601729    1.24895687    1.57851557    1.80697221\n",
      "    2.25402829    2.67966085    2.88123522    2.19200447    1.84082469\n",
      "    1.44009707    1.25218986    0.97101662    0.89157513    0.76710311\n",
      "    0.73912278    0.6512003     0.68037602    0.69750597    0.78879756\n",
      "    0.64265046    0.80342745    0.79280453    0.81813337    0.87121581\n",
      "    0.76690238    0.89017495    1.00391105    1.16053566    1.48992873\n",
      "    1.80093612    3.04987976    5.27097241    9.62231847    9.22856434\n",
      "    5.38082301    2.91218819    2.02439271    1.45499242    1.12233277\n",
      "    0.96154327    0.91478474    0.75816799    0.86867997    0.82988233\n",
      "    0.90363207    0.76112107    0.82665428    0.94226382    1.03724245\n",
      "    1.27879249    2.03936141    4.62970359   18.14665502   57.92073501\n",
      "   43.74476786   11.10619814    3.34332657    1.78673749    1.15668622\n",
      "    1.222865      0.95188002    0.90058728    1.20077131    1.15008761\n",
      "    1.19314278    1.7558814     3.93906244   19.28737331  101.39273557\n",
      "   45.45536747    6.9163439     2.02061151    1.42959433    1.04373557\n",
      "    1.62747558    2.0165784     5.63464141   22.37664853    7.75865177\n",
      "    2.36875429    4.23204108]\n"
     ]
    }
   ],
   "source": [
    "# Example pattern from x=2.6264, y=-17.96082\n",
    "\n",
    "# The range of x and y is [-47.884375 cm, -47.884375 cm]\n",
    "# But x**2 + y**2 < 47.884375**2\n",
    "# Otherwise m() will raise and exception\n",
    "\n",
    "pattern = model(2.6264, -17.96082)\n",
    "\n",
    "print(\"Length of pattern: %d, Sum of pattern: %.2f\" % (len(pattern), pattern.sum()))\n",
    "print(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.115222817130077, -15.358220637996187)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If using a 2D Normal prior this would be a good guess for the mean (x,y) of that prior.\n",
    "prior_mean(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Function for sampling proposal coordinates from the prior: Normal Centered on the naiveCoord, sd=15\n",
    "def priorFunction(coord):\n",
    "    coordX = coord[0]\n",
    "    coordY = coord[1]\n",
    "    xProp=np.random.normal(coordX,15,1)[0]\n",
    "    yProp=np.random.normal(coordY,15,1)[0]\n",
    "    while xProp**2+yProp**2>47.884375**2:\n",
    "        xProp=np.random.normal(coordX,15,1)[0]\n",
    "        yProp=np.random.normal(coordY,15,1)[0]\n",
    "    return xProp,yProp\n",
    "#priorFunction(naiveCoord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Distance function for comparing the real and the simulated dataset\n",
    "def rho(x,y):\n",
    "    return sum((x-y)**2)/np.shape(x)[0]\n",
    "    #return sum(np.abs(x-y))/np.shape(x)[0]\n",
    "#print(rho(event,SimulatedModel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Load the true position matrix for generating the Observed dataset\n",
    "\n",
    "###For sure you can load only the positions from the original files but I got errors when trying to call the data\n",
    "\n",
    "trueCoordMatrix=np.loadtxt('truepos')\n",
    "#print(trueCoordMatrix[0])\n",
    "#np.shape(trueCoordMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###ABC-SMC Definition of the necessary quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Transformation kernel for resampling for t>0 (i.e. rather the using the prior we use this kernel)\n",
    "def transfKernel(propx0,propy0,varx,vary):\n",
    "    propx=np.random.normal(propx0,2*varx,1)[0]\n",
    "    propy=np.random.normal(propy0,2*vary,1)[0]\n",
    "    while propx**2+propy**2 > 47.884375**2:\n",
    "        propx=np.random.normal(propx0,2*varx,1)[0]\n",
    "        propy=np.random.normal(propy0,2*vary,1)[0]\n",
    "    return propx,propy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###ABC-SMC on a single selected event event j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "###Number of particles for recunstructing the posterior for each coordinate\n",
    "N=5000\n",
    "\n",
    "###Number of iterations before stopping the algorithm\n",
    "nIter=40\n",
    "\n",
    "###Quantile used for shrinking the tolerances through the iterations\n",
    "quantile=0.85\n",
    "\n",
    "###Importance weigths for the ABC-PMC: because for t>0 we using a kernel and not the prior as proposal distribution\n",
    "weights=np.zeros((nIter,N))\n",
    "weights[0,:]=1/N\n",
    "\n",
    "###Accepted elements are stored here\n",
    "###abcCooord x\n",
    "abcCoordsx=np.zeros((nIter,N))\n",
    "###abcCooord y\n",
    "abcCoordsy=np.zeros((nIter,N))\n",
    "\n",
    "###Distance of accepted elements are stored here\n",
    "d=np.zeros((nIter,N))\n",
    "\n",
    "###First tolerance epsilon1\n",
    "epsilon=4\n",
    "\n",
    "###Total number of draws required for covering the entire analyses\n",
    "totDraws=0\n",
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "###pick the event j\n",
    "j=0\n",
    "\n",
    "###given an event, we need the true coordinates of this event and getting the 'true' dataset. The trueDataset called here\n",
    "###TrueModel\n",
    "trueCoord = trueCoordMatrix[j] \n",
    "TrueModel=model(trueCoord[0], trueCoord[1], 500)\n",
    "###means of the priors\n",
    "naiveCoord=prior_mean(TrueModel)\n",
    "\n",
    "###Simulated accepted dataset from the last iteration\n",
    "simAccData=np.zeros((N,np.shape(TrueModel)[0]))\n",
    "    \n",
    "for t in range(0,nIter):\n",
    "    print(t)\n",
    "    if(t==0):\n",
    "        for i in range(0,N):\n",
    "            d[t,i]=epsilon+1\n",
    "            while d[t,i] > epsilon: \n",
    "                propCoord = priorFunction(naiveCoord)\n",
    "                ###Deterministic FM\n",
    "                #simulatedData = model(propCoord[0], propCoord[1], 500)\n",
    "                ###Stochastic FM, for now adding gaussian noise (mean=0,sd=1)\n",
    "                simulatedData = model(propCoord[0], propCoord[1], 500)+np.random.normal(0,1,np.shape(TrueModel)[0])\n",
    "                totDraws = totDraws+1\n",
    "                d[t,i] = rho(TrueModel,simulatedData) \n",
    "            abcCoordsx[t,i]=propCoord[0]\n",
    "            abcCoordsy[t,i]=propCoord[1]\n",
    "    else:\n",
    "        epsilon= np.percentile(d[t-1,],quantile*100)\n",
    "        print(epsilon)\n",
    "        meanx=np.sum(abcCoordsx[t-1,:]*weights[t-1,:])\n",
    "        varx=np.sum((abcCoordsx[t-1,:]-meanx)**2*weights[t-1,:])\n",
    "        meany=np.sum(abcCoordsy[t-1,:]*weights[t-1,:])\n",
    "        vary=np.sum((abcCoordsy[t-1,:]-meany)**2*weights[t-1,:])\n",
    "        for i in range(0,N):\n",
    "            d[t,i]=epsilon+1\n",
    "            while d[t,i] > epsilon: \n",
    "                sample=np.random.choice(N,1,p=weights[t-1,:])\n",
    "                propx0=abcCoordsx[t-1,sample]\n",
    "                propy0=abcCoordsy[t-1,sample]\n",
    "                prop=transfKernel(propx0,propy0,varx,vary)\n",
    "                propx=prop[0]\n",
    "                propy=prop[1]\n",
    "                ###Deterministic FM\n",
    "                #simulatedData = model(propx, propy, 500)\n",
    "                ###Stochastic FM, for now adding gaussian noise (mean=0,sd=1)\n",
    "                simulatedData = model(propx, propy, 500)+np.random.normal(0,1,np.shape(TrueModel)[0])\n",
    "                totDraws = totDraws+1\n",
    "                d[t,i] = rho(TrueModel,simulatedData)\n",
    "            simAccData[i,:]=simulatedData\n",
    "            abcCoordsx[t,i]=propx\n",
    "            abcCoordsy[t,i]=propy \n",
    "            weightsDen=np.sum(weights[t-1,:]*scipy.stats.norm.pdf(propx,abcCoordsx[t-1,:],np.sqrt(2*varx))*scipy.stats.norm.pdf(propy,abcCoordsy[t-1,:],np.sqrt(2*vary)))\n",
    "            weightsNum=scipy.stats.norm.pdf(propx,propCoord[0],10)*scipy.stats.norm.pdf(propy,propCoord[1],10)     \n",
    "            weights[t,i]=weightsNum/weightsDen\n",
    "    weights[t,:]=weights[t,:]/sum(weights[t,:])\n",
    "print(totDraws)\n",
    "abcOutput=np.column_stack((abcCoordsx[nIter-1,:],abcCoordsy[nIter-1,:]))\n",
    "np.savetxt('abcPosteriorCoords_%d.dat'%(j), abcOutput)\n",
    "importanceWeigths=weights[nIter-1,:]\n",
    "np.savetxt('WeightsabcPosteriorCoords_%d.dat'%(j), importanceWeigths)\n",
    "np.savetxt('simAccData_%d.dat'%(j), simAccData)\n",
    "np.savetxt('TrueData_%d.dat'%(j), TrueModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3246]\n"
     ]
    }
   ],
   "source": [
    "###I pick randomly 10 elements for the analyses\n",
    "elements=np.random.choice(np.shape(trueCoordMatrix)[0],1)\n",
    "print(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3246\n",
      "0.875631205344\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "###ABCPMC for all the events or a random selection among the possbilities\n",
    "#for j in np.random.choice(np.shape(trueCoordMatrix)[0],10):\n",
    "#for j in range(0,1): \n",
    "for j in elements:\n",
    "    print(j)\n",
    "    N=5000\n",
    "    nIter=40\n",
    "    quantile=0.85\n",
    "    epsilon=4\n",
    "    ###Importance weigths for the ABC-PMC\n",
    "    weights=np.zeros((nIter,N))\n",
    "    weights[0,:]=1/N\n",
    "    ###abcCooord x\n",
    "    abcCoordsx=np.zeros((nIter,N))\n",
    "    ###abcCooord y\n",
    "    abcCoordsy=np.zeros((nIter,N))\n",
    "    ###Distance\n",
    "    d=np.zeros((nIter,N)) \n",
    "    \n",
    "    trueCoord = trueCoordMatrix[j]\n",
    "    TrueModel=model(trueCoord[0], trueCoord[1], 500)\n",
    "    naiveCoord=prior_mean(TrueModel)\n",
    "    totDraws=0\n",
    "    t=0\n",
    "    for t in range(0,nIter):\n",
    "        #print(t)\n",
    "        if(t==0):\n",
    "            for i in range(0,N):\n",
    "                d[t,i]=epsilon+1\n",
    "                while d[t,i] > epsilon: \n",
    "                    propCoord = priorFunction(naiveCoord)\n",
    "                    ###Deterministic FM\n",
    "                    #simulatedData = model(propCoord[0], propCoord[1], 500)\n",
    "                    ###Stochastic FM, for now adding gaussian noise (mean=0,sd=1)\n",
    "                    simulatedData = model(propCoord[0], propCoord[1], 500)+np.random.normal(0,1,np.shape(TrueModel)[0])\n",
    "                    totDraws = totDraws+1\n",
    "                    d[t,i] = rho(TrueModel,simulatedData)\n",
    "                abcCoordsx[t,i]=propCoord[0]\n",
    "                abcCoordsy[t,i]=propCoord[1]\n",
    "        else:\n",
    "            epsilon= np.percentile(d[t-1,],quantile*100)\n",
    "            #print(epsilon)\n",
    "            meanx=np.sum(abcCoordsx[t-1,:]*weights[t-1,:])\n",
    "            varx=np.sum((abcCoordsx[t-1,:]-meanx)**2*weights[t-1,:])\n",
    "            meany=np.sum(abcCoordsy[t-1,:]*weights[t-1,:])\n",
    "            vary=np.sum((abcCoordsy[t-1,:]-meany)**2*weights[t-1,:])\n",
    "            for i in range(0,N):\n",
    "                d[t,i]=epsilon+1\n",
    "                while d[t,i] > epsilon: \n",
    "                    sample=np.random.choice(N,1,p=weights[t-1,:])\n",
    "                    propx0=abcCoordsx[t-1,sample]\n",
    "                    propy0=abcCoordsy[t-1,sample]\n",
    "                    prop=transfKernel(propx0,propy0,varx,vary)\n",
    "                    propx=prop[0]\n",
    "                    propy=prop[1]\n",
    "                    ###Deterministic FM\n",
    "                    #simulatedData = model(propx, propy, 500)\n",
    "                    ###Stochastic FM, for now adding gaussian noise (mean=0,sd=1)\n",
    "                    simulatedData = model(propx, propy, 500)+np.random.normal(0,1,np.shape(TrueModel)[0])\n",
    "                    totDraws = totDraws+1\n",
    "                    d[t,i] = rho(TrueModel,simulatedData)\n",
    "                abcCoordsx[t,i]=propx\n",
    "                abcCoordsy[t,i]=propy\n",
    "                weightsDen=np.sum(weights[t-1,:]*scipy.stats.norm.pdf(propx,abcCoordsx[t-1,:],np.sqrt(2*varx))*scipy.stats.norm.pdf(propy,abcCoordsy[t-1,:],np.sqrt(2*vary)))\n",
    "                weightsNum=scipy.stats.norm.pdf(propx,propCoord[0],10)*scipy.stats.norm.pdf(propy,propCoord[1],10)     \n",
    "                weights[t,i]=weightsNum/weightsDen\n",
    "        weights[t,:]=weights[t,:]/sum(weights[t,:])\n",
    "    ###here we save the coordinated saved in the last iteration, and corresponding weights.\n",
    "    abcOutput=np.column_stack((abcCoordsx[nIter-1,:],abcCoordsy[nIter-1,:]))\n",
    "    np.savetxt('abcPosteriorCoords_%d.dat'%(j), abcOutput)\n",
    "    importanceWeigths=weights[nIter-1,:]\n",
    "    np.savetxt('WeightsabcPosteriorCoords_%d.dat'%(j), importanceWeigths)\n",
    "    print(epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
